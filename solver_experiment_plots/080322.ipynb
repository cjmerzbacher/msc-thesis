{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import grad\n",
    "from torchdiffeq import odeint_adjoint\n",
    "from torchdiffeq import odeint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StiffODE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StiffODE, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.tensor([1.]), requires_grad=True)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        dy = self.W*y**2 - y**3\n",
    "        return torch.stack([dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(true_y, pred):\n",
    "    return ((true_y-pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = StiffODE()\n",
    "learning_rate = 0.01\n",
    "num_iters = 100\n",
    "optimizer = optim.Adam(func.parameters(), amsgrad=False, lr=learning_rate)\n",
    "solver = 'dopri8'\n",
    "\n",
    "np.random.seed(2021)\n",
    "plt.close('all')\n",
    "\n",
    "delta = 0.02\n",
    "y0 = torch.tensor([delta])\n",
    "t = torch.linspace(0, 2/delta, 100, requires_grad=False) \n",
    "\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f93986219a0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Establish initial conditions\n",
    "pred = odeint(func, y0, t, method=solver)\n",
    "plt.plot(pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotte/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function _UncheckedAssignBackward returned an invalid gradient at index 1 - got [1, 1] but expected shape compatible with [1, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m loss(true_y, pred)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloss_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function _UncheckedAssignBackward returned an invalid gradient at index 1 - got [1, 1] but expected shape compatible with [1, 1, 1]"
     ]
    }
   ],
   "source": [
    "loss_val = loss(true_y, pred)\n",
    "loss_val.backward(retain_graph=True)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr loss theta_0 theta_1\n",
      "0 2.485819189661173e+33 -0.1 0.1\n",
      "10 2.485819189661173e+33 0.8348 0.9084\n",
      "20 2.485819189661173e+33 1.7499 1.805\n",
      "30 2.485819189661173e+33 2.2075 2.5735\n",
      "40 2.485819189661173e+33 2.2075 2.9247\n",
      "50 2.485819189661173e+33 2.2075 3.1895\n",
      "60 2.485819189661173e+33 2.2075 3.4186\n",
      "70 2.485819189661173e+33 2.2075 3.6274\n",
      "80 2.485819189661173e+33 2.2075 3.8231\n",
      "90 2.485819189661173e+33 2.2075 4.0096\n",
      "100 2.485819189661173e+33 2.2075 4.1895\n",
      "110 2.485819189661173e+33 2.2075 4.3643\n",
      "120 2.485819189661173e+33 2.2075 4.5352\n",
      "130 2.485819189661173e+33 2.2075 4.703\n",
      "140 2.485819189661173e+33 2.2075 4.7363\n",
      "150 2.485819189661173e+33 2.2075 4.7363\n",
      "160 2.485819189661173e+33 2.2075 4.7363\n",
      "170 2.485819189661173e+33 2.2075 4.7363\n",
      "180 2.485819189661173e+33 2.2075 4.7363\n",
      "190 2.485819189661173e+33 2.2075 4.7363\n",
      "200 2.485819189661173e+33 2.2075 4.7363\n",
      "210 2.485819189661173e+33 2.2075 4.7363\n",
      "220 2.485819189661173e+33 2.2075 4.7363\n",
      "230 2.485819189661173e+33 2.2075 4.7363\n",
      "240 2.485819189661173e+33 2.2075 4.7363\n",
      "250 2.485819189661173e+33 2.2075 4.7363\n",
      "260 2.485819189661173e+33 2.2075 4.7363\n",
      "270 2.485819189661173e+33 2.2075 4.7363\n",
      "280 2.485819189661173e+33 2.2075 4.7363\n",
      "290 2.485819189661173e+33 2.2075 4.7363\n",
      "300 2.485819189661173e+33 2.2075 4.7363\n",
      "310 2.485819189661173e+33 2.2075 4.7363\n",
      "320 2.485819189661173e+33 2.2075 4.7363\n",
      "330 2.485819189661173e+33 2.2075 4.7363\n",
      "340 2.485819189661173e+33 2.2075 4.7363\n",
      "350 2.485819189661173e+33 2.2075 4.7363\n",
      "360 2.485819189661173e+33 2.2075 4.7363\n",
      "370 2.485819189661173e+33 2.2075 4.7363\n",
      "380 2.485819189661173e+33 2.2075 4.7363\n",
      "390 2.485819189661173e+33 2.2075 4.7363\n",
      "400 2.485819189661173e+33 2.2075 4.7363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters): \n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_y0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdopri5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#pred = odeint_adjoint(func, true_y0, t, method='dopri5')\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fun(true_y_noise, pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:255\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    250\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/rk_common.py:76\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     74\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m     75\u001b[0m     yi \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmatmul(beta_i \u001b[38;5;241m*\u001b[39m dt)\u001b[38;5;241m.\u001b[39mview_as(f0)\n\u001b[0;32m---> 76\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tableau\u001b[38;5;241m.\u001b[39mbeta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:189\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mODEFun.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[1;32m     11\u001b[0m     S, I \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m---> 12\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mS\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[43mS\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m     13\u001b[0m     di \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mS\u001b[38;5;241m*\u001b[39mI \u001b[38;5;241m-\u001b[39m I\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([ds, di])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/_tensor.py:30\u001b[0m, in \u001b[0;36m_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def loss_fun(gt, pred):\n",
    "    return ((gt-pred)**2).mean()\n",
    "    \n",
    "\n",
    "class ODEFun(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ODEFun, self).__init__()\n",
    "        self.theta = torch.nn.Parameter(torch.tensor([0.0, 0.0]), requires_grad=True)\n",
    "        \n",
    "    def forward(self, t, y):\n",
    "        S, I = y\n",
    "        ds = self.theta[0]*S**2 - self.theta[1]*S**3\n",
    "        di = self.theta[1]*S*I - I\n",
    "        return torch.stack([ds, di])\n",
    "\n",
    "def gt_fun(t, y):\n",
    "    theta_0 = 5.5\n",
    "    theta_1 = 8.0\n",
    "    S, I = y\n",
    "    ds = theta_0*S**2 - theta_1*S**3\n",
    "    di = theta_1*S*I - I\n",
    "    return torch.stack([ds, di])\n",
    "        \n",
    "true_y0 = torch.tensor([0.99, 0.01])\n",
    "t = torch.linspace(0, 10, 100) \n",
    "\n",
    "\n",
    "# gt\n",
    "with torch.no_grad():\n",
    "    true_y = odeint(gt_fun, true_y0, t, method='dopri5')\n",
    "    true_y_noise = true_y + torch.randn(true_y.shape)*0.02\n",
    "    #true_y_adj = odeint_adjoint(gt_fun, true_y0, t, method='dopri5')\n",
    "\n",
    "\n",
    "func = ODEFun()\n",
    "lr = 0.01\n",
    "num_iters = 1000\n",
    "optimizer = torch.optim.RMSprop(func.parameters(), lr=lr)\n",
    "\n",
    "print('itr loss theta_0 theta_1')\n",
    "for ii in range(num_iters): \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = odeint(func, true_y0, t, method='dopri5')\n",
    "    #pred = odeint_adjoint(func, true_y0, t, method='dopri5')\n",
    "    loss = loss_fun(true_y_noise, pred)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ii % 10 == 0:\n",
    "        print(ii, round(loss.item(), 4), round(func.theta[0].item(), 4), round(func.theta[1].item(), 4))\n",
    "    \n",
    "\n",
    "# Note: here the GT values are hardcoded - fix\n",
    "print('\\n')\n",
    "print('GT  : theta_0: {:2.2}, theta_1: {:2.2}'.format(5.5, 8.0))\n",
    "print('Pred: theta_0: {:2.2}, theta_1: {:2.2}'.format(round(func.theta[0].item(), 4), round(func.theta[1].item(), 4)))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "with torch.no_grad():\n",
    "    plt.plot(t, true_y[:,0], 'C0', lw=3, label='S GT')\n",
    "    plt.plot(t, true_y[:,1], 'C1', lw=3, label='I GT')\n",
    "    plt.plot(t, pred[:,0], 'k', lw=1, label='S Pred')\n",
    "    plt.plot(t, pred[:,1], ':k', lw=1, label='I Pred')\n",
    "plt.legend()\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fee36ad9d78978217c6d83218886f2e57823a4ec68da675ae41cb4d953e9a6e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
